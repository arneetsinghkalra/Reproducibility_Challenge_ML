{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "cnn2_modelnet-Behnaz.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oAM3NMtqyqYJ",
        "zQLfFY832RTk",
        "_XyDEDQvzD1z",
        "g3TTIl5AzJdR",
        "0ut0c7Hr07gb",
        "1x6KpeR70aq2",
        "gh5BrWS0vxoH",
        "kCeNIEfjv9bS",
        "V3hV_oduwDmC",
        "5rYQU_M4wQkn",
        "NzWSgv9Hsig8",
        "4KOJCDFuvdLz",
        "-zyZE7dG5bpr",
        "C4m84k07IULx",
        "v5icoxcG8aid",
        "mVMD00Oz9ZTV"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odIlr0U81SzA",
        "outputId": "f04fea27-731e-4988-8827-5daa8f386d0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3My7_1Xk1zFx"
      },
      "source": [
        "import sys\n",
        "# store the dataset.7z file in MiniProject4\n",
        "sys.path.insert(0,'/content/gdrive/MyDrive/Colab Notebooks/MiniProject4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6291mQPdvn0l"
      },
      "source": [
        "import os \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import tensorflow as tf \n",
        "import tensorflow.keras as keras\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import utils_modelnet as ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz0vuMbszfoV"
      },
      "source": [
        "# Main Code provided by the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAM3NMtqyqYJ"
      },
      "source": [
        "## Data loading and pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQLfFY832RTk"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yImfWBv0v08",
        "outputId": "8ba52c43-c512-4863-d81a-3aa5fef287ba"
      },
      "source": [
        "!7z x '/content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 437541578 bytes (418 MiB)\n",
            "\n",
            "Extracting archive: /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z\n",
            "--\n",
            "Path = /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z\n",
            "Type = 7z\n",
            "Physical Size = 437541578\n",
            "Headers Size = 459592\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 84\b\b\b\b\b\b\b       \b\b\b\b\b\b\b  0% 84 - dataset/modelnet2d/airplane/1/1.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 694 - dataset/modelnet2d/airplane/1/65.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 1346 - dataset/modelnet2d/airplane/10/69.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 1894 - dataset/modelnet2d/airplane/11/562.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 1895 - dataset/modelnet2d/airplane/11/563.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 2528 - dataset/modelnet2d/airplane/12/55.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 3150 - dataset/modelnet2d/airplane/13/526.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 3826 - dataset/modelnet2d/airplane/14/551.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 4553 - dataset/modelnet2d/airplane/15/622.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 5624 - dataset/modelnet2d/airplane/3/42.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 6143 - dataset/modelnet2d/airplane/4/303.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 7203 - dataset/modelnet2d/airplane/5/91.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 7604 - dataset/modelnet2d/airplane/6/452.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 8882 - dataset/modelnet2d/airplane/8/436.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 9018 - dataset/modelnet2d/airplane/8/559.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 9954 - dataset/modelnet2d/car/1/234.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 10257 - dataset/modelnet2d/car/1/507.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 10650 - dataset/modelnet2d/car/10/278.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 11161 - dataset/modelnet2d/car/11/154.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11162 - dataset/modelnet2d/car/11/155.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11614 - dataset/modelnet2d/car/11/562.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11649 - dataset/modelnet2d/car/11/594.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11773 - dataset/modelnet2d/car/12/121.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 12009 - dataset/modelnet2d/car/12/334.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 12324 - dataset/modelnet2d/car/12/618.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 12324 - dataset/modelnet2d/car/12/618.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 12768 - dataset/modelnet2d/car/13/434.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 12815 - dataset/modelnet2d/car/13/477.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 13293 - dataset/modelnet2d/car/14/323.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 13759 - dataset/modelnet2d/car/15/16.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 14294 - dataset/modelnet2d/car/15/641.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 14746 - dataset/modelnet2d/car/2/465.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 15208 - dataset/modelnet2d/car/3/298.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 15712 - dataset/modelnet2d/car/4/168.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 16281 - dataset/modelnet2d/car/4/97.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 16805 - dataset/modelnet2d/car/5/569.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17209 - dataset/modelnet2d/car/6/349.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17485 - dataset/modelnet2d/car/6/598.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17887 - dataset/modelnet2d/car/7/376.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 18360 - dataset/modelnet2d/car/8/218.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 18766 - dataset/modelnet2d/car/8/584.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 19195 - dataset/modelnet2d/car/9/387.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 19680 - dataset/modelnet2d/chair/1/24.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 20327 - dataset/modelnet2d/chair/10/239.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 20869 - dataset/modelnet2d/chair/11/143.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 21325 - dataset/modelnet2d/chair/11/554.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 22000 - dataset/modelnet2d/chair/12/579.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 22042 - dataset/modelnet2d/chair/12/616.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 22537 - dataset/modelnet2d/chair/13/479.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23010 - dataset/modelnet2d/chair/14/320.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23358 - dataset/modelnet2d/chair/14/634.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23671 - dataset/modelnet2d/chair/15/332.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23943 - dataset/modelnet2d/chair/15/578.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 24666 - dataset/modelnet2d/chair/2/645.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 25232 - dataset/modelnet2d/chair/3/571.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 25720 - dataset/modelnet2d/chair/4/427.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 26201 - dataset/modelnet2d/chair/5/277.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 26833 - dataset/modelnet2d/chair/6/262.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 27262 - dataset/modelnet2d/chair/6/65.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 27545 - dataset/modelnet2d/chair/7/32.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 28247 - dataset/modelnet2d/chair/8/369.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 28975 - dataset/modelnet2d/chair/9/440.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 29449 - dataset/modelnet2d/lamp/1/284.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 29710 - dataset/modelnet2d/lamp/1/519.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 30381 - dataset/modelnet2d/lamp/10/54.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 31348 - dataset/modelnet2d/lamp/12/243.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 31705 - dataset/modelnet2d/lamp/12/565.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 32494 - dataset/modelnet2d/lamp/14/108.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 33171 - dataset/modelnet2d/lamp/15/134.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 33664 - dataset/modelnet2d/lamp/15/579.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 33774 - dataset/modelnet2d/lamp/15/94.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 34646 - dataset/modelnet2d/lamp/3/296.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 35299 - dataset/modelnet2d/lamp/4/30.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 35483 - dataset/modelnet2d/lamp/4/466.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 35767 - dataset/modelnet2d/lamp/5/138.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 36493 - dataset/modelnet2d/lamp/6/208.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 37089 - dataset/modelnet2d/lamp/7/161.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 37741 - dataset/modelnet2d/lamp/8/165.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 37914 - dataset/modelnet2d/lamp/8/320.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 38648 - dataset/modelnet2d/lamp/9/399.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 39179 - dataset/modelnet2d/person/1/293.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 39605 - dataset/modelnet2d/person/1/93.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 40132 - dataset/modelnet2d/person/10/568.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 40623 - dataset/modelnet2d/person/11/426.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 41086 - dataset/modelnet2d/person/12/26.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 41500 - dataset/modelnet2d/person/12/632.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 42119 - dataset/modelnet2d/person/13/606.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 42613 - dataset/modelnet2d/person/14/468.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 43101 - dataset/modelnet2d/person/15/323.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 43347 - dataset/modelnet2d/person/15/545.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 43693 - dataset/modelnet2d/person/2/273.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 44167 - dataset/modelnet2d/person/3/116.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 44615 - dataset/modelnet2d/person/3/52.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 45040 - dataset/modelnet2d/person/4/319.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 45434 - dataset/modelnet2d/person/4/90.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 45918 - dataset/modelnet2d/person/5/526.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 46402 - dataset/modelnet2d/person/6/379.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 46863 - dataset/modelnet2d/person/7/21.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 47276 - dataset/modelnet2d/person/7/582.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 47827 - dataset/modelnet2d/person/8/495.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 48353 - dataset/modelnet2d/person/9/385.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 84\n",
            "Files: 48607\n",
            "Size:       1226655670\n",
            "Compressed: 437541578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XyDEDQvzD1z"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c65DR06kvn0n",
        "outputId": "4033ed3f-4206-45e6-fe7e-13237a7d3073"
      },
      "source": [
        "dataset_path = 'dataset/modelnet2d/'\n",
        "class_set =  ['chair', 'car', 'lamp', 'airplane', 'person']\n",
        "\n",
        "dataset = ds.get_data_from_file(class_set, dataset_path)\n",
        "train_dataset, valid_dataset, test_dataset = ds.train_test_split(dataset)\n",
        "\n",
        "train_data, train_label = ds.split_data_label(train_dataset)\n",
        "test_data, test_label = ds.split_data_label(test_dataset)\n",
        "valid_data, valid_label = ds.split_data_label(valid_dataset)\n",
        "## train and validation\n",
        "print(\"Train Dataset: {}\".format(len(train_dataset)))\n",
        "print(\"Test Dataset: {}\".format(len(test_dataset)))\n",
        "print(\"Valid Dataset: {}\".format(len(valid_dataset)))\n",
        "num_classes = len(class_set)\n",
        "print(\"Number of Classes: {}\".format(num_classes))\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 48\n",
        "NUM_CHANNEL = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Dataset: 10800\n",
            "Test Dataset: 32400\n",
            "Valid Dataset: 5400\n",
            "Number of Classes: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3TTIl5AzJdR"
      },
      "source": [
        "### Preparing binocular images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ-MM0ylvn0o"
      },
      "source": [
        "def get_binocular_dataset(data, label, batch_size=BATCH_SIZE):\n",
        "    def preprocess_image(left_image, right_image):\n",
        "        left_image = tf.image.decode_jpeg(left_image, channels=NUM_CHANNEL)\n",
        "        left_image = tf.image.resize(left_image, [IMG_SIZE, IMG_SIZE])\n",
        "        left_image /= 255.0\n",
        "\n",
        "        right_image = tf.image.decode_jpeg(right_image, channels=NUM_CHANNEL)\n",
        "        right_image = tf.image.resize(right_image, [IMG_SIZE, IMG_SIZE])\n",
        "        right_image /= 255.0  # normalize to [0,1] range\n",
        "        return left_image, right_image\n",
        "\n",
        "    def load_and_preprocess_image(left, right):\n",
        "        left_image = tf.io.read_file(left)\n",
        "        right_image = tf.io.read_file(right)\n",
        "        return preprocess_image(left_image, right_image)\n",
        "\n",
        "    # The tuples are unpacked into the positional arguments of the mapped function \n",
        "    def load_and_preprocess_from_path_label(data_path, label):\n",
        "        return load_and_preprocess_image(data_path[0], data_path[1]), label\n",
        "    \n",
        "    ds = tf.data.Dataset.from_tensor_slices((data, label))\n",
        "    ds = ds.map(load_and_preprocess_from_path_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds = ds.shuffle(buffer_size=len(data))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    print(ds)\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqwMKOYIvn0o",
        "outputId": "fa0883c3-8c39-4c2e-ca7f-8c97ada3005c"
      },
      "source": [
        "train_ds = get_binocular_dataset(train_data, train_label)\n",
        "test_ds = get_binocular_dataset(test_data, test_label)\n",
        "valid_ds = get_binocular_dataset(valid_data, valid_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: (((None, 48, 48, 1), (None, 48, 48, 1)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\n",
            "<PrefetchDataset shapes: (((None, 48, 48, 1), (None, 48, 48, 1)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\n",
            "<PrefetchDataset shapes: (((None, 48, 48, 1), (None, 48, 48, 1)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ut0c7Hr07gb"
      },
      "source": [
        "## CNN2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x6KpeR70aq2"
      },
      "source": [
        "### Defining Monocular layer including cmpooling and Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNs_dnuvn0o"
      },
      "source": [
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.max_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps\n",
        "\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5BrWS0vxoH"
      },
      "source": [
        "### Defining CNN2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVn6oG2svn0p"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYm_mO4Dvn0p"
      },
      "source": [
        "def create_model(model, input_shape, num_classes, scale_list):\n",
        "    m = model(input_shape, num_classes, scale_list)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCeNIEfjv9bS"
      },
      "source": [
        "### Create and fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClrO2unaKdHF",
        "outputId": "35416d06-5ce4-463c-aff8-2152691467e8"
      },
      "source": [
        "cnn2 = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2.fit(train_ds , epochs=10, validation_data=valid_ds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.7943 - sparse_categorical_accuracy: 0.7154 - val_loss: 0.1203 - val_sparse_categorical_accuracy: 0.9630\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9713\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0873 - val_sparse_categorical_accuracy: 0.9719\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0538 - val_sparse_categorical_accuracy: 0.9820\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0865 - val_sparse_categorical_accuracy: 0.9678\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.0300 - val_sparse_categorical_accuracy: 0.9915\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0454 - val_sparse_categorical_accuracy: 0.9830\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.1208 - val_sparse_categorical_accuracy: 0.9572\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0228 - val_sparse_categorical_accuracy: 0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe132bd1050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3hV_oduwDmC"
      },
      "source": [
        "### Evaluation on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jCRUnPOpN96",
        "outputId": "50c4d686-09dd-4b91-92bd-b295fdd6a158"
      },
      "source": [
        "loss, acc = cnn2.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9940\n",
            "Loss: 0.018022213131189346, Acc: 0.9939814805984497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rYQU_M4wQkn"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzWSgv9Hsig8"
      },
      "source": [
        "## Using different number of scales in CMPooling (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH1eW9g_6Git"
      },
      "source": [
        "We changed the scal_list variable to [1,3] and [1,3,5,7] to see the effect of using less and more scales on the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KeyKAR3tZqc"
      },
      "source": [
        "### Using 2 scales: 1, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_pFe4VjtDPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e75915-23cd-4951-ec58-bda748419a37"
      },
      "source": [
        "SCALE_LIST = [1,3]\n",
        "cnn2_2scales = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_2scales.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 20s 28ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.0826 - val_sparse_categorical_accuracy: 0.9731\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9891\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0279 - val_sparse_categorical_accuracy: 0.9919\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0246 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 0.9909\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 20s 29ms/step - loss: 0.0197 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0216 - val_sparse_categorical_accuracy: 0.9939\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9928\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0247 - val_sparse_categorical_accuracy: 0.9931\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0366 - val_sparse_categorical_accuracy: 0.9876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f13aedd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf46fdjHtYPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e75c40b-4217-44f1-873e-ee22f25b9f25"
      },
      "source": [
        "loss, acc = cnn2_2scales.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9865\n",
            "Loss: 0.04089761897921562, Acc: 0.9865123629570007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjwiXrF7th91"
      },
      "source": [
        "### Using 4 scales: 1, 3, 5, 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR_-uzxmtsuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f828a9-3eba-4f9d-bac9-77bb508848d7"
      },
      "source": [
        "SCALE_LIST = [1,3,5,7]\n",
        "cnn2_4scales = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_4scales.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 24ms/step - loss: 0.9522 - sparse_categorical_accuracy: 0.6308 - val_loss: 0.1602 - val_sparse_categorical_accuracy: 0.9507\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 23ms/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9730\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.0916 - val_sparse_categorical_accuracy: 0.9654\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.0559 - val_sparse_categorical_accuracy: 0.9811\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9648\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0404 - val_sparse_categorical_accuracy: 0.9861\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.9831\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 23ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 23ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 23ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0329 - val_sparse_categorical_accuracy: 0.9891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f041edd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBE6AkTAttJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01241fce-2bb1-435e-fcb6-17b1cf5c2ed6"
      },
      "source": [
        "loss, acc = cnn2_4scales.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 33s 4ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9905\n",
            "Loss: 0.02878613770008087, Acc: 0.9905247092247009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUny5LR_Zpd"
      },
      "source": [
        "We can see the accuracy when we use [1,3,5] as scale list is better than the other two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KOJCDFuvdLz"
      },
      "source": [
        "## Pooling after Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2IQUlVJ7QC0"
      },
      "source": [
        "investigating the effect of placing cmpooling after conv layer on the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqQREuVgxagr"
      },
      "source": [
        "### Updated Monocular layer for Pooling after Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA0G8qw_vjZ7"
      },
      "source": [
        "# Changing SCALE_LIST to the original one\n",
        "SCALE_LIST = [1,3,5]\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = cmpooling(conv_maps, scale_list, pool_stride)\n",
        "        return tf.concat(pool_maps, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxOMerF7x2mX"
      },
      "source": [
        "### Create and fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkj9oVgRw2P_",
        "outputId": "e33933c3-1b8c-41e9-956e-34e00f1ad621"
      },
      "source": [
        "cnn2_inverseP = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_inverseP.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 21s 28ms/step - loss: 0.8101 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9626\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0487 - val_sparse_categorical_accuracy: 0.9831\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 20s 28ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 0.9813\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 0.9920\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0394 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0183 - val_sparse_categorical_accuracy: 0.9941\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0163 - val_sparse_categorical_accuracy: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f1556050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr1IHz2wyD0G"
      },
      "source": [
        "### Evaluation on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1D9dGdRw5Nt",
        "outputId": "ec382da2-c477-41af-a2a4-1a220084ccb3"
      },
      "source": [
        "loss, acc = cnn2_inverseP.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 5ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9960\n",
            "Loss: 0.013400280848145485, Acc: 0.9959567785263062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zyZE7dG5bpr"
      },
      "source": [
        "## Ablation study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zneefPnJ936A"
      },
      "source": [
        "### 1) Concentric multi-scale (CM) pooling contribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-DfKo_38XSs"
      },
      "source": [
        "Using Maxpooling instead of CMPooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ClXpHq_T8w"
      },
      "source": [
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = tf.keras.layers.MaxPooling2D((2, 2), pool_stride, \"SAME\")(fmaps)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzowsZ4WEKXi",
        "outputId": "c3ed75c1-7853-48d8-981c-4b8e3c7fdea8"
      },
      "source": [
        "cnn2_maxPool = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_maxPool.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 20s 28ms/step - loss: 0.8976 - sparse_categorical_accuracy: 0.6637 - val_loss: 0.1714 - val_sparse_categorical_accuracy: 0.9450\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9661\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9724 - val_loss: 0.0482 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0424 - val_sparse_categorical_accuracy: 0.9889\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0308 - val_sparse_categorical_accuracy: 0.9920\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9920\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0193 - val_sparse_categorical_accuracy: 0.9963\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 0.9939\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0191 - val_sparse_categorical_accuracy: 0.9946\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 19s 28ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0e672ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owom9YXkEcQ6",
        "outputId": "c83da9d3-ac20-4987-f17c-ab7cef4d0fa1"
      },
      "source": [
        "loss, acc = cnn2_maxPool.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 5ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9938\n",
            "Loss: 0.02324630320072174, Acc: 0.9937654137611389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-b0L2BUm1zA"
      },
      "source": [
        "### 2) Changing MaxPooling to AvgPooling in CMPooling layer (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E2PXb_duf5m"
      },
      "source": [
        "# Changing the Monocular to the original one\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTKyxUfAuydz"
      },
      "source": [
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.avg_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJTmTcExseC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b9d9f9-9140-48cb-e7cc-3e7ad4c22f18"
      },
      "source": [
        "cnn2_CM_avgPooling = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_CM_avgPooling.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 25ms/step - loss: 0.7789 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.1299 - val_sparse_categorical_accuracy: 0.9537\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1273 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.0767 - val_sparse_categorical_accuracy: 0.9719\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1188 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0444 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0339 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9735\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0207 - val_sparse_categorical_accuracy: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0e637a290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5fS_Ytx1J8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f552e75c-42b9-473c-dddf-a45c71391738"
      },
      "source": [
        "loss, acc = cnn2.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 33s 4ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9940\n",
            "Loss: 0.01860054023563862, Acc: 0.993950605392456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0o60YHBZwi"
      },
      "source": [
        "### 3) One feedforward pathways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDDEbG8RC9MV"
      },
      "source": [
        "# Changing the cmpooling to the original one\n",
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.max_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bup9MMv0De4u"
      },
      "source": [
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = tf.keras.layers.MaxPooling2D((2, 2), pool_stride, \"SAME\")(conv_maps)\n",
        "        \n",
        "        return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJb3udZDDhj3"
      },
      "source": [
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    x = tf.concat([left_eye, right_eye], axis=-1)\n",
        "\n",
        "    x = Monocular(6, 5, input_shape=input_shape, name='mono1')(x, scale_list=scale_list, pool_stride=2)    \n",
        "    x = Monocular(12, 5, name='mono2')(x, scale_list=scale_list, pool_stride=1)    \n",
        "    x = Monocular(32, 3, name='mono3')(x, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njyrpYWUD99_",
        "outputId": "49923713-5b29-4f23-ad1e-47ceb60b23a5"
      },
      "source": [
        "cnn2_1fP = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_1fP.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 27ms/step - loss: 0.9160 - sparse_categorical_accuracy: 0.6652 - val_loss: 0.1371 - val_sparse_categorical_accuracy: 0.9563\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.1243 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1572 - val_sparse_categorical_accuracy: 0.9426\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9804 - val_loss: 0.0752 - val_sparse_categorical_accuracy: 0.9767\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0521 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.0519 - val_sparse_categorical_accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9907\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0337 - val_sparse_categorical_accuracy: 0.9889\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0398 - val_sparse_categorical_accuracy: 0.9859\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 0.9922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f15ffe90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K36Xi99DGaEc",
        "outputId": "7e9375af-105b-4dde-c04c-376059248eed"
      },
      "source": [
        "loss, acc = cnn2_1fP.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9942\n",
            "Loss: 0.021849771961569786, Acc: 0.9941975474357605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV3QInjn_cxH"
      },
      "source": [
        "### 4) Changing number of (CMPooling + conv) layers (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xst5okyhw8n8"
      },
      "source": [
        "# Changing the Monocular to the original one\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59uhoXeIxI1j"
      },
      "source": [
        "2 (CMPooling + conv) layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK0craItxQHT"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left2, right2], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN-rNWMEyHTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c87134-e335-4b2c-e8d4-8ed828fd16a8"
      },
      "source": [
        "cnn2_2cm_conv_layers = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_2cm_conv_layers.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 25ms/step - loss: 0.8166 - sparse_categorical_accuracy: 0.6949 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9467\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.1287 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9665\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.0564 - val_sparse_categorical_accuracy: 0.9826\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.0576 - val_sparse_categorical_accuracy: 0.9804\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0523 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0462 - val_sparse_categorical_accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0298 - val_sparse_categorical_accuracy: 0.9911\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0266 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0249 - val_sparse_categorical_accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0477 - val_sparse_categorical_accuracy: 0.9867\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0f0547f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyT45ezwyJZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39bb19e9-401f-4758-b0f6-6220ac061b95"
      },
      "source": [
        "loss, acc = cnn2_2cm_conv_layers.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 33s 4ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9934\n",
            "Loss: 0.021721355617046356, Acc: 0.9933642148971558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOiT6FxCxRIQ"
      },
      "source": [
        "4 (CMPooling + conv) layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJG6PY2wxURv"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left4 = Monocular(64, 3, name='mono4_left')(tf.concat([left3, right3], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right4 = Monocular(64, 3, name='mono4_right')(tf.concat([right3, left3], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "\n",
        "    x = tf.concat([left4, right4], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-zpsYq_y-QA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03da413-da00-403a-9420-0579f565e4ad"
      },
      "source": [
        "cnn2_4cm_conv_layers = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_4cm_conv_layers.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 20s 26ms/step - loss: 0.7916 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9494\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1573 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.0606 - val_sparse_categorical_accuracy: 0.9811\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0473 - val_sparse_categorical_accuracy: 0.9852\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.0653 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 26ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0477 - val_sparse_categorical_accuracy: 0.9826\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0385 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0247 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0e240ad50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCbbsbjSzAnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8750f5b5-b627-4df0-8fe1-d32a94426f48"
      },
      "source": [
        "loss, acc = cnn2_4cm_conv_layers.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 33s 4ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9925\n",
            "Loss: 0.02171819470822811, Acc: 0.9925000071525574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXtdwGQ86FH3"
      },
      "source": [
        "### 5) Without augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYVe9yF6VnJ"
      },
      "source": [
        "CNN2 without Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8OYyKn6Z7M"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    left = left_eye\n",
        "    right = right_eye\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i_r8rFO6sMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357f19be-28c7-40c1-fabf-304aac5c58d3"
      },
      "source": [
        "cnn2_WoAug = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_WoAug.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.7021 - val_loss: 0.2407 - val_sparse_categorical_accuracy: 0.9107\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1457 - sparse_categorical_accuracy: 0.9460 - val_loss: 0.1491 - val_sparse_categorical_accuracy: 0.9448\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9645 - val_loss: 0.0754 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0610 - val_sparse_categorical_accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9902\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0313 - val_sparse_categorical_accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0161 - val_sparse_categorical_accuracy: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0c85a3bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnSAQSp7ARP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0427da0-f164-4973-e6bb-ca3f70b8fea8"
      },
      "source": [
        "loss, acc = cnn2_WoAug.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9958\n",
            "Loss: 0.01327881682664156, Acc: 0.995771586894989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4m84k07IULx"
      },
      "source": [
        "## Fusion of the Two Feedforward Pathways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFOEr6RsIn5A"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "\n",
        "    left2 = Monocular(12, 5, name='mono2_left')(left1, scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(right1, scale_list=scale_list, pool_stride=1)\n",
        "\n",
        "    left3 = Monocular(32, 3, name='mono3_left')(left2, scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(right2, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5EEo5CI91M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7bd44e-dafa-44ce-ad3d-77465ffda7fe"
      },
      "source": [
        "cnn2_fu = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_fu.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 25ms/step - loss: 1.0622 - sparse_categorical_accuracy: 0.5998 - val_loss: 0.2013 - val_sparse_categorical_accuracy: 0.9333\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 25ms/step - loss: 0.1633 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1140 - val_sparse_categorical_accuracy: 0.9617\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.0934 - val_sparse_categorical_accuracy: 0.9665\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0841 - val_sparse_categorical_accuracy: 0.9689\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0453 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9896\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0270 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9906\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.0200 - val_sparse_categorical_accuracy: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0c81b40d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t3PB2LOJAOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e6eefb-3826-4f1d-f9d0-3e7bd4d6dd6f"
      },
      "source": [
        "loss, acc = cnn2_fu.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9928\n",
            "Loss: 0.019315484911203384, Acc: 0.9928086400032043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5icoxcG8aid"
      },
      "source": [
        "# Vanilla CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74JBzOdK8bWT"
      },
      "source": [
        "def CNN(input_shape, num_classes):\n",
        "    \n",
        "    left_eye= tf.keras.Input(shape=input_shape, name = 'left_eye')\n",
        "    right_eye= tf.keras.Input(shape=input_shape, name = 'right_eye')\n",
        "    \n",
        "    parallax = left_eye - right_eye \n",
        "    x = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(6, 5,  activation='relu', padding= 'same', name = 'mono1_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    x = tf.keras.layers.Conv2D(12, 5, activation='relu', padding= 'same', name='mono2_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(1,1))(x)\n",
        "    x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding= 'same', name='mono3_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(1,1))(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='output')(feature_vector)\n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxFm7SYMlAg"
      },
      "source": [
        "def create_model(model, input_shape, num_classes):\n",
        "    m = model(input_shape, num_classes)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlJwTcDU9Jw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687db068-37a6-40b5-9b20-fd958a8b79a9"
      },
      "source": [
        "cnn = create_model(CNN, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5)\n",
        "cnn.fit(train_ds , epochs=10, validation_data=valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.9657 - sparse_categorical_accuracy: 0.6468 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9389\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9796\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0442 - val_sparse_categorical_accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 26ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.0310 - val_sparse_categorical_accuracy: 0.9915\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 26ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9915\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0182 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9919\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 19s 26ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 26ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9946\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 26ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0be3addd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIwsFp6f9N6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022ce664-cb29-4652-c865-fb104b8d380e"
      },
      "source": [
        "loss, acc = cnn.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 34s 4ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9956\n",
            "Loss: 0.01468063984066248, Acc: 0.995555579662323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVMD00Oz9ZTV"
      },
      "source": [
        "## VanillaCNN with CMPooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ8ov3is9aFz"
      },
      "source": [
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = cmpooling(conv_maps, scale_list, pool_stride)\n",
        "        return tf.concat(pool_maps, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Och6oMzn-4of"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN(input_shape, num_classes, scale_list):\n",
        "    \n",
        "    left_eye= tf.keras.Input(shape=input_shape, name = 'left_eye')\n",
        "    right_eye= tf.keras.Input(shape=input_shape, name = 'right_eye')\n",
        "    \n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "\n",
        "    y = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    y = Monocular(12, 5, input_shape=input_shape, name='mono2_left')(y, scale_list=scale_list, pool_stride=1)\n",
        "    y = Monocular(32, 3, input_shape=input_shape, name='mono3_left')(y, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    y = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(y)\n",
        "    y = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(y)\n",
        "    y = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(y)\n",
        "    feature_vector = tf.keras.layers.Flatten()(y)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='output')(feature_vector)\n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9WNIU14My06"
      },
      "source": [
        "def create_model(model, input_shape, num_classes, scale_list):\n",
        "    m = model(input_shape, num_classes, scale_list)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ULRq5qv-8_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d677277-c04d-4ef3-e28d-8312b4c5c34c"
      },
      "source": [
        "cnn_cmp = create_model(CNN, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn_cmp.fit(train_ds , epochs=10, validation_data=valid_ds, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "338/338 [==============================] - 19s 25ms/step - loss: 0.8702 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.1958 - val_sparse_categorical_accuracy: 0.9291\n",
            "Epoch 2/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9759\n",
            "Epoch 3/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9848\n",
            "Epoch 4/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0491 - val_sparse_categorical_accuracy: 0.9852\n",
            "Epoch 5/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 6/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0300 - val_sparse_categorical_accuracy: 0.9911\n",
            "Epoch 7/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0340 - val_sparse_categorical_accuracy: 0.9885\n",
            "Epoch 8/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9872\n",
            "Epoch 9/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0312 - val_sparse_categorical_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "338/338 [==============================] - 18s 24ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0465 - val_sparse_categorical_accuracy: 0.9874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0be214210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMYclcE1--0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a119ab24-e2a0-4085-c508-ac0777cedd64"
      },
      "source": [
        "loss, acc = cnn_cmp.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 33s 4ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9852\n",
            "Loss: 0.04395705461502075, Acc: 0.9852468967437744\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}