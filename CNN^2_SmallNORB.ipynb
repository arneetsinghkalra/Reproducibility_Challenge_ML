{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "CNN^2-SmallNORB",
      "provenance": [],
      "collapsed_sections": [
        "oAM3NMtqyqYJ",
        "zQLfFY832RTk",
        "_XyDEDQvzD1z",
        "g3TTIl5AzJdR",
        "0ut0c7Hr07gb",
        "1x6KpeR70aq2",
        "gh5BrWS0vxoH",
        "kCeNIEfjv9bS",
        "V3hV_oduwDmC",
        "5rYQU_M4wQkn",
        "9KeyKAR3tZqc",
        "fjwiXrF7th91",
        "4KOJCDFuvdLz",
        "zneefPnJ936A",
        "V-b0L2BUm1zA",
        "NZ0o60YHBZwi",
        "cV3QInjn_cxH",
        "yXtdwGQ86FH3",
        "C4m84k07IULx",
        "v5icoxcG8aid",
        "mVMD00Oz9ZTV"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odIlr0U81SzA",
        "outputId": "ec33eb5c-a166-49d9-d012-904f90d1c4d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6291mQPdvn0l"
      },
      "source": [
        "import time\n",
        "import os \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import tensorflow as tf \n",
        "import tensorflow.keras as keras\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz0vuMbszfoV"
      },
      "source": [
        "# Main Code provided by the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAM3NMtqyqYJ"
      },
      "source": [
        "## Data loading and pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQLfFY832RTk"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yImfWBv0v08",
        "outputId": "6f7a9fc7-6dad-43dd-8898-dc198ae7c464"
      },
      "source": [
        "!7z x '/content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 437541578 bytes (418 MiB)\n",
            "\n",
            "Extracting archive: /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z\n",
            "--\n",
            "Path = /content/gdrive/MyDrive/Colab Notebooks/MiniProject4/dataset.7z\n",
            "Type = 7z\n",
            "Physical Size = 437541578\n",
            "Headers Size = 459592\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 84\b\b\b\b\b\b\b       \b\b\b\b\b\b\b  0% 557 - dataset/modelnet2d/airplane/1/525.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 694 - dataset/modelnet2d/airplane/1/65.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 1175 - dataset/modelnet2d/airplane/10/499.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 1894 - dataset/modelnet2d/airplane/11/562.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 2479 - dataset/modelnet2d/airplane/12/505.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 3150 - dataset/modelnet2d/airplane/13/526.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 3926 - dataset/modelnet2d/airplane/14/641.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 4553 - dataset/modelnet2d/airplane/15/622.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 5588 - dataset/modelnet2d/airplane/3/388.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 6143 - dataset/modelnet2d/airplane/4/303.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 7194 - dataset/modelnet2d/airplane/5/83.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 7604 - dataset/modelnet2d/airplane/6/452.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 8927 - dataset/modelnet2d/airplane/8/477.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 9114 - dataset/modelnet2d/airplane/8/645.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 9954 - dataset/modelnet2d/car/1/234.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 10257 - dataset/modelnet2d/car/1/507.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 10650 - dataset/modelnet2d/car/10/278.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11161 - dataset/modelnet2d/car/11/154.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11649 - dataset/modelnet2d/car/11/594.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 12046 - dataset/modelnet2d/car/12/368.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 12325 - dataset/modelnet2d/car/12/619.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 12807 - dataset/modelnet2d/car/13/47.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 13293 - dataset/modelnet2d/car/14/323.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 13759 - dataset/modelnet2d/car/15/16.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 14294 - dataset/modelnet2d/car/15/641.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 14746 - dataset/modelnet2d/car/2/465.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 15208 - dataset/modelnet2d/car/3/298.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 15712 - dataset/modelnet2d/car/4/168.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 16281 - dataset/modelnet2d/car/4/97.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 16810 - dataset/modelnet2d/car/5/573.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17366 - dataset/modelnet2d/car/6/490.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17501 - dataset/modelnet2d/car/6/611.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 17886 - dataset/modelnet2d/car/7/375.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 18360 - dataset/modelnet2d/car/8/218.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 18766 - dataset/modelnet2d/car/8/584.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 19195 - dataset/modelnet2d/car/9/387.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 19680 - dataset/modelnet2d/chair/1/24.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 20327 - dataset/modelnet2d/chair/10/239.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 20869 - dataset/modelnet2d/chair/11/143.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 21325 - dataset/modelnet2d/chair/11/554.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 21981 - dataset/modelnet2d/chair/12/561.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 22076 - dataset/modelnet2d/chair/12/647.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 22538 - dataset/modelnet2d/chair/13/48.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23010 - dataset/modelnet2d/chair/14/320.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23519 - dataset/modelnet2d/chair/15/196.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 23942 - dataset/modelnet2d/chair/15/577.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 24666 - dataset/modelnet2d/chair/2/645.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 25232 - dataset/modelnet2d/chair/3/571.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 25720 - dataset/modelnet2d/chair/4/427.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 26201 - dataset/modelnet2d/chair/5/277.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 26833 - dataset/modelnet2d/chair/6/262.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 27514 - dataset/modelnet2d/chair/7/292.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 27735 - dataset/modelnet2d/chair/7/491.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 28247 - dataset/modelnet2d/chair/8/369.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 28542 - dataset/modelnet2d/chair/8/634.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 28975 - dataset/modelnet2d/chair/9/440.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 29648 - dataset/modelnet2d/lamp/1/463.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 30381 - dataset/modelnet2d/lamp/10/54.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 30532 - dataset/modelnet2d/lamp/10/92.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 31348 - dataset/modelnet2d/lamp/12/243.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 31349 - dataset/modelnet2d/lamp/12/244.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 32133 - dataset/modelnet2d/lamp/13/367.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 32494 - dataset/modelnet2d/lamp/14/108.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 33171 - dataset/modelnet2d/lamp/15/134.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 33774 - dataset/modelnet2d/lamp/15/94.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 34182 - dataset/modelnet2d/lamp/2/461.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 34647 - dataset/modelnet2d/lamp/3/297.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 35299 - dataset/modelnet2d/lamp/4/30.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 35767 - dataset/modelnet2d/lamp/5/138.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 36493 - dataset/modelnet2d/lamp/6/208.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 36898 - dataset/modelnet2d/lamp/6/573.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 37227 - dataset/modelnet2d/lamp/7/286.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 37832 - dataset/modelnet2d/lamp/8/247.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 38648 - dataset/modelnet2d/lamp/9/399.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 39179 - dataset/modelnet2d/person/1/293.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 39595 - dataset/modelnet2d/person/1/84.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 39921 - dataset/modelnet2d/person/10/378.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 40132 - dataset/modelnet2d/person/10/568.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 40623 - dataset/modelnet2d/person/11/426.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 41086 - dataset/modelnet2d/person/12/26.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 41500 - dataset/modelnet2d/person/12/632.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 41881 - dataset/modelnet2d/person/13/392.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 42119 - dataset/modelnet2d/person/13/606.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 42614 - dataset/modelnet2d/person/14/469.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 43151 - dataset/modelnet2d/person/15/369.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 43692 - dataset/modelnet2d/person/2/272.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 44167 - dataset/modelnet2d/person/3/116.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 44614 - dataset/modelnet2d/person/3/519.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 45039 - dataset/modelnet2d/person/4/318.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 45433 - dataset/modelnet2d/person/4/9.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 45918 - dataset/modelnet2d/person/5/526.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 46402 - dataset/modelnet2d/person/6/379.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 46863 - dataset/modelnet2d/person/7/21.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 47276 - dataset/modelnet2d/person/7/582.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 47827 - dataset/modelnet2d/person/8/495.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 48354 - dataset/modelnet2d/person/9/386.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 48686 - dataset/smallnorb/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 48689 - dataset/smallnorb/smallnorb-5 . x18x6x2x96x96-training-dat.mat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 84\n",
            "Files: 48607\n",
            "Size:       1226655670\n",
            "Compressed: 437541578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XyDEDQvzD1z"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk3H_NQ-9ZFL"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def getPath(which_set, filetype, dirname='data'):\n",
        "    \"\"\"\n",
        "    Getting the path for the desired dataset.\n",
        "    which_set: train, test\n",
        "    filetype: dat, cat, info\n",
        "    \"\"\"     \n",
        "    if which_set == 'train':\n",
        "        instance_list = '46789'\n",
        "    elif which_set == 'test':\n",
        "        instance_list = '01235'\n",
        "    filename = 'smallnorb-5x%sx9x18x6x2x96x96-%s-%s.mat' % \\\n",
        "        (instance_list, which_set + 'ing', filetype)\n",
        "    return os.path.join(dirname, filename)\n",
        "\n",
        "\n",
        "def readNums(file_handle, num_type, count):\n",
        "    \"\"\"\n",
        "    Reads 4 bytes from file, returns it as a 32-bit integer.\n",
        "    \"\"\"\n",
        "    num_bytes = count * np.dtype(num_type).itemsize\n",
        "    string = file_handle.read(num_bytes)\n",
        "    return np.fromstring(string, dtype=num_type)\n",
        "\n",
        "\n",
        "def readHeader(file_handle, debug=False):\n",
        "    \"\"\"\n",
        "    Reads the header of the file.\n",
        "    file_handle: an open file handle.\n",
        "    returns: data type, element size, rank, shape, size\n",
        "    \"\"\"\n",
        "\n",
        "    key_to_type = {0x1E3D4C51: ('float32', 4),\n",
        "                   # 0x1E3D4C52 : ('packed matrix', 0),\n",
        "                   0x1E3D4C53: ('float64', 8),\n",
        "                   0x1E3D4C54: ('int32', 4),\n",
        "                   0x1E3D4C55: ('uint8', 1),\n",
        "                   0x1E3D4C56: ('int16', 2)}\n",
        "\n",
        "    type_key = readNums(file_handle, 'int32', 1)[0]\n",
        "    elem_type, elem_size = key_to_type[type_key]\n",
        "    if debug:\n",
        "        print(\"header's type key, type, type size: \",\n",
        "              type_key, elem_type, elem_size)\n",
        "    if elem_type == 'packed matrix':\n",
        "        raise NotImplementedError('packed matrix not supported')\n",
        "\n",
        "    num_dims = readNums(file_handle, 'int32', 1)[0]\n",
        "    if debug:\n",
        "        print('# of dimensions, according to header: ', num_dims)\n",
        "\n",
        "    shape = np.fromfile(file_handle,\n",
        "                        dtype='int32',\n",
        "                        count=max(num_dims, 3))[:num_dims]\n",
        "\n",
        "    if debug:\n",
        "        print('Tensor shape, as listed in header:', shape)\n",
        "\n",
        "    return elem_type, elem_size, shape\n",
        "\n",
        "\n",
        "def parseNORBFile(file_handle, debug=False):\n",
        "    \"\"\"\n",
        "    Parse file into numpy array and return.\n",
        "    file_handle: an open file handle.\n",
        "    \"\"\"\n",
        "    elem_type, elem_size, shape = readHeader(file_handle, debug)\n",
        "    beginning = file_handle.tell()\n",
        "    num_elems = np.prod(shape)\n",
        "    result = np.fromfile(file_handle,\n",
        "                         dtype=elem_type,\n",
        "                         count=num_elems).reshape(shape)\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_data(which_set='train', file_type='dat', path='data', debug=True):\n",
        "    file_path = getPath(which_set, file_type, path)\n",
        "    file_handle = open(file_path, 'rb')\n",
        "    norb_data = parseNORBFile(file_handle, debug)\n",
        "    return norb_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c65DR06kvn0n"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1q8j1Zb-yYR",
        "outputId": "f61d369b-3cb1-44c8-b07d-1728234fc541"
      },
      "source": [
        "dataset_path = \"dataset/smallnorb/\"\n",
        "train_info = get_data('train', 'info', dataset_path, debug=False)\n",
        "raw_train_data = get_data('train', 'dat', dataset_path, debug=False)\n",
        "raw_train_label = get_data('train', 'cat', dataset_path, debug=False)\n",
        "\n",
        "test_info = get_data('test', 'info', dataset_path, debug=False)\n",
        "raw_test_data = get_data('test', 'dat', dataset_path, debug=False)\n",
        "raw_test_label = get_data('test', 'cat', dataset_path, debug=False)\n",
        "\n",
        "train_info = np.concatenate([raw_train_label[:, np.newaxis], train_info], axis=-1)\n",
        "test_info = np.concatenate([raw_test_label[:, np.newaxis], test_info], axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBbeV64f_TfK"
      },
      "source": [
        "data = np.concatenate([raw_train_data, raw_test_data], axis=0)\n",
        "label = np.concatenate([raw_train_label, raw_test_label], axis=0)\n",
        "info = np.concatenate([train_info, test_info], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc_GqpCc_US7"
      },
      "source": [
        "def sort_info(data, label, info):\n",
        "    feat_order = info.view('i4,i4,i4,i4,i4').argsort(kind='mergesort', order=['f0', 'f3', 'f2', 'f1', 'f4'], axis=0).reshape(-1)\n",
        "    data, label = data[feat_order], label[feat_order]\n",
        "    info = info[feat_order]#[label_order]\n",
        "    return data, label, info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5UIdi1t_b5W"
      },
      "source": [
        "all_data, all_label, all_info = sort_info(data, label, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yISOLd5X_XJ2"
      },
      "source": [
        "def split_train_test(data):\n",
        "    num_classes = 5\n",
        "    data_per_class = len(data) // num_classes\n",
        "    viewpoint = 18\n",
        "    train_viewpoint = 6 / 18\n",
        "    \n",
        "    train_idx, test_idx = [], []\n",
        "    for i in range(num_classes):\n",
        "        train_idx.extend(range(i * data_per_class, i * data_per_class + int(data_per_class * train_viewpoint)))\n",
        "        test_idx.extend(range(i * data_per_class + int(data_per_class * train_viewpoint), (i+1) * data_per_class))\n",
        "    return train_idx, test_idx\n",
        "\n",
        "train_idx, test_idx = split_train_test(all_data)\n",
        "train_data, test_data = all_data[train_idx], all_data[test_idx]\n",
        "train_label, test_label = all_label[train_idx], all_label[test_idx]\n",
        "train_info, test_info = all_info[train_idx], all_info[test_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3TTIl5AzJdR"
      },
      "source": [
        "### Preparing binocular images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ-MM0ylvn0o"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 48\n",
        "def get_binocular_dataset(data, label, batch_size=BATCH_SIZE):\n",
        "    def preprocess_image(left_image, right_image):\n",
        "        left_image = tf.expand_dims(left_image, -1)\n",
        "        left_image = tf.image.resize(left_image, [IMG_SIZE, IMG_SIZE])\n",
        "        left_image /= 255.0\n",
        "\n",
        "        right_image = tf.expand_dims(right_image, -1)\n",
        "        right_image = tf.image.resize(right_image, [IMG_SIZE, IMG_SIZE])\n",
        "        right_image /= 255.0  # normalize to [0,1] range\n",
        "        return left_image, right_image\n",
        "\n",
        "    def load_and_preprocess_image(binocular_images):\n",
        "        left_image, right_image = binocular_images[0], binocular_images[1]\n",
        "        return preprocess_image(left_image, right_image)\n",
        "\n",
        "    # The tuples are unpacked into the positional arguments of the mapped function \n",
        "    def load_and_preprocess_from_path_label(data_path, label):\n",
        "        return load_and_preprocess_image(data_path), label\n",
        "    \n",
        "    ds = tf.data.Dataset.from_tensor_slices((data, label))\n",
        "    ds = ds.map(load_and_preprocess_from_path_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds = ds.shuffle(buffer_size=len(data))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    print(ds)\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqwMKOYIvn0o",
        "outputId": "1ca324e0-2d21-4808-ea46-675c87d2f013"
      },
      "source": [
        "train_ds = get_binocular_dataset(train_data, train_label)\n",
        "test_ds = get_binocular_dataset(test_data, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: (((None, 48, 48, 1), (None, 48, 48, 1)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\n",
            "<PrefetchDataset shapes: (((None, 48, 48, 1), (None, 48, 48, 1)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ut0c7Hr07gb"
      },
      "source": [
        "## CNN2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x6KpeR70aq2"
      },
      "source": [
        "### Defining Monocular layer including cmpooling and Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNs_dnuvn0o"
      },
      "source": [
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.max_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps\n",
        "\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5BrWS0vxoH"
      },
      "source": [
        "### Defining CNN2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVn6oG2svn0p"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.7)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYm_mO4Dvn0p"
      },
      "source": [
        "def create_model(model, input_shape, num_classes, scale_list):\n",
        "    m = model(input_shape, num_classes, scale_list)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCeNIEfjv9bS"
      },
      "source": [
        "### Create and fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClrO2unaKdHF",
        "outputId": "243d9e3b-0084-4b78-c091-1808d24f98d6"
      },
      "source": [
        "start = time.time()\n",
        "cnn2 = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2.fit(train_ds , epochs=10, validation_data=test_ds)\n",
        "end = time.time()\n",
        "print(f'Running time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 44s 22ms/step - loss: 0.9980 - sparse_categorical_accuracy: 0.5822 - val_loss: 0.5336 - val_sparse_categorical_accuracy: 0.7996\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.2212 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.5423 - val_sparse_categorical_accuracy: 0.8229\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.5155 - val_sparse_categorical_accuracy: 0.8495\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.8184\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.8501\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.8171 - val_sparse_categorical_accuracy: 0.8300\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.8592\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.8677\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.8609\n",
            "Running time: 150.19094800949097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3hV_oduwDmC"
      },
      "source": [
        "### Evaluation on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jCRUnPOpN96",
        "outputId": "0cd01fa4-f39a-4dc9-fa18-eb7a6d8ab1a4"
      },
      "source": [
        "loss, acc = cnn2.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 6s 4ms/step - loss: 0.4420 - sparse_categorical_accuracy: 0.9052\n",
            "Loss: 0.4420419931411743, Acc: 0.9052160382270813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rYQU_M4wQkn"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzWSgv9Hsig8"
      },
      "source": [
        "## Using different number of scales in CMPooling (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH1eW9g_6Git"
      },
      "source": [
        "We changed the scal_list variable to [1,3] and [1,3,5,7] to see the effect of using less and more scales on the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KeyKAR3tZqc"
      },
      "source": [
        "### Using 2 scales: 1, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_pFe4VjtDPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c61ba0e-c826-489a-d489-caacc6b160d4"
      },
      "source": [
        "SCALE_LIST = [1,3]\n",
        "cnn2_2scales = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_2scales.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 14s 23ms/step - loss: 1.0243 - sparse_categorical_accuracy: 0.5661 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.7622\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.1990 - sparse_categorical_accuracy: 0.9279 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.8067\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.7344 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.8283 - val_sparse_categorical_accuracy: 0.8435\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.8413 - val_sparse_categorical_accuracy: 0.8513\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.8572 - val_sparse_categorical_accuracy: 0.8525\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.9446 - val_sparse_categorical_accuracy: 0.8469\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.8647\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.9279 - val_sparse_categorical_accuracy: 0.8675\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.9575 - val_sparse_categorical_accuracy: 0.8551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa60564da10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf46fdjHtYPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25142ef-96a0-4e12-fdb8-39b73c5d698b"
      },
      "source": [
        "loss, acc = cnn2_2scales.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 5ms/step - loss: 0.9575 - sparse_categorical_accuracy: 0.8551\n",
            "Loss: 0.9575446248054504, Acc: 0.8550925850868225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjwiXrF7th91"
      },
      "source": [
        "### Using 4 scales: 1, 3, 5, 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR_-uzxmtsuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ce78a0-1da2-4822-c91a-ec2ef8845522"
      },
      "source": [
        "SCALE_LIST = [1,3,5,7]\n",
        "cnn2_4scales = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_4scales.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 11s 18ms/step - loss: 1.1150 - sparse_categorical_accuracy: 0.5220 - val_loss: 0.8657 - val_sparse_categorical_accuracy: 0.6835\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.3297 - sparse_categorical_accuracy: 0.8811 - val_loss: 0.6372 - val_sparse_categorical_accuracy: 0.7795\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9405 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.8196\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.5090 - val_sparse_categorical_accuracy: 0.8432\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.6125 - val_sparse_categorical_accuracy: 0.8418\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.7235 - val_sparse_categorical_accuracy: 0.8228\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0347 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.7448 - val_sparse_categorical_accuracy: 0.8257\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.6048 - val_sparse_categorical_accuracy: 0.8612\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.5902 - val_sparse_categorical_accuracy: 0.8678\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 10s 17ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.8728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5fb4bca10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBE6AkTAttJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ba6211-4931-4900-a983-8c57e90d42aa"
      },
      "source": [
        "loss, acc = cnn2_4scales.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 6s 4ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.8728\n",
            "Loss: 0.6038768291473389, Acc: 0.8727777600288391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUny5LR_Zpd"
      },
      "source": [
        "We can see the accuracy when we use [1,3,5] as scale list is better than the other two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KOJCDFuvdLz"
      },
      "source": [
        "## Pooling after Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2IQUlVJ7QC0"
      },
      "source": [
        "investigating the effect of placing cmpooling after conv layer on the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqQREuVgxagr"
      },
      "source": [
        "### Updated Monocular layer for Pooling after Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA0G8qw_vjZ7"
      },
      "source": [
        "# Changing SCALE_LIST to the original one\n",
        "SCALE_LIST = [1,3,5]\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = cmpooling(conv_maps, scale_list, pool_stride)\n",
        "        return tf.concat(pool_maps, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxOMerF7x2mX"
      },
      "source": [
        "### Create and fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkj9oVgRw2P_",
        "outputId": "0a191fe6-905e-4336-b8b3-a135d9f761dc"
      },
      "source": [
        "cnn2_inverseP = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_inverseP.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 14s 24ms/step - loss: 0.9562 - sparse_categorical_accuracy: 0.6003 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.7788\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.4928 - val_sparse_categorical_accuracy: 0.8618\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.5512 - val_sparse_categorical_accuracy: 0.8547\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.8826\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.4737 - val_sparse_categorical_accuracy: 0.8921\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.8863\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.8820\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.4249 - val_sparse_categorical_accuracy: 0.9085\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.5339 - val_sparse_categorical_accuracy: 0.8965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa6052c9b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr1IHz2wyD0G"
      },
      "source": [
        "### Evaluation on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1D9dGdRw5Nt",
        "outputId": "2ce6cca5-1c5a-4eb0-d9a5-e12750e6a313"
      },
      "source": [
        "loss, acc = cnn2_inverseP.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 4ms/step - loss: 0.5339 - sparse_categorical_accuracy: 0.8965\n",
            "Loss: 0.5339114665985107, Acc: 0.8964506387710571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zyZE7dG5bpr"
      },
      "source": [
        "## Ablation study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zneefPnJ936A"
      },
      "source": [
        "### 1) Concentric multi-scale (CM) pooling contribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-DfKo_38XSs"
      },
      "source": [
        "Using Maxpooling instead of CMPooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ClXpHq_T8w"
      },
      "source": [
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = tf.keras.layers.MaxPooling2D((2, 2), pool_stride, \"SAME\")(fmaps)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzowsZ4WEKXi",
        "outputId": "02c4f9ee-f4c3-47f0-965f-323cc67ff0dc"
      },
      "source": [
        "cnn2_maxPool = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_maxPool.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 14s 24ms/step - loss: 1.0394 - sparse_categorical_accuracy: 0.5524 - val_loss: 0.7981 - val_sparse_categorical_accuracy: 0.7282\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.2383 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9553 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.8375\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9702 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.8514\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.7617 - val_sparse_categorical_accuracy: 0.8436\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.7848 - val_sparse_categorical_accuracy: 0.8446\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.8602\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.9603 - val_sparse_categorical_accuracy: 0.8553\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.9600 - val_sparse_categorical_accuracy: 0.8528\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.8665 - val_sparse_categorical_accuracy: 0.8606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa6052d9490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owom9YXkEcQ6",
        "outputId": "637f7821-1381-4188-a5dd-0044c111bdc2"
      },
      "source": [
        "loss, acc = cnn2_maxPool.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 5ms/step - loss: 0.8665 - sparse_categorical_accuracy: 0.8606\n",
            "Loss: 0.866533637046814, Acc: 0.8606481552124023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-b0L2BUm1zA"
      },
      "source": [
        "### 2) Changing MaxPooling to AvgPooling in CMPooling layer (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E2PXb_duf5m"
      },
      "source": [
        "# Changing the Monocular to the original one\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTKyxUfAuydz"
      },
      "source": [
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.avg_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJTmTcExseC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a896ee-dc51-4218-ea2c-751020c19284"
      },
      "source": [
        "cnn2_CM_avgPooling = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_CM_avgPooling.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 12s 20ms/step - loss: 1.0428 - sparse_categorical_accuracy: 0.5758 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.7395\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.3307 - sparse_categorical_accuracy: 0.8771 - val_loss: 0.7388 - val_sparse_categorical_accuracy: 0.7624\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.2052 - sparse_categorical_accuracy: 0.9265 - val_loss: 0.5369 - val_sparse_categorical_accuracy: 0.8194\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.4935 - val_sparse_categorical_accuracy: 0.8413\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.8315\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8774\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.8843\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.5159 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.8856\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.8692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa605573c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5fS_Ytx1J8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c773eb81-6a7d-4e19-e399-6934366f96cd"
      },
      "source": [
        "loss, acc = cnn2.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 6s 4ms/step - loss: 0.4420 - sparse_categorical_accuracy: 0.9052\n",
            "Loss: 0.4420417547225952, Acc: 0.9052160382270813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0o60YHBZwi"
      },
      "source": [
        "### 3) One feedforward pathways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDDEbG8RC9MV"
      },
      "source": [
        "# Changing the cmpooling to the original one\n",
        "## Utility function\n",
        "def cmpooling(fmaps, scale_list, pool_stride):\n",
        "    # make sure the scale_list is in decending order\n",
        "    if scale_list[0] - scale_list[1] < 0:\n",
        "        scale_list = scale_list[::-1]\n",
        "        \n",
        "    # concentric multi-scale pooling\n",
        "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
        "    pool_maps = []\n",
        "    for offset, scale in zip(offset, scale_list):\n",
        "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
        "        pool_map = tf.nn.max_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
        "        pool_maps.append(pool_map)\n",
        "    \n",
        "    # assert same shape for all pool_map\n",
        "    for i in range(len(pool_maps)-1):\n",
        "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
        "    return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bup9MMv0De4u"
      },
      "source": [
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = tf.keras.layers.MaxPooling2D((2, 2), pool_stride, \"SAME\")(conv_maps)\n",
        "        \n",
        "        return pool_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJb3udZDDhj3"
      },
      "source": [
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    x = tf.concat([left_eye, right_eye], axis=-1)\n",
        "\n",
        "    x = Monocular(6, 5, input_shape=input_shape, name='mono1')(x, scale_list=scale_list, pool_stride=2)    \n",
        "    x = Monocular(12, 5, name='mono2')(x, scale_list=scale_list, pool_stride=1)    \n",
        "    x = Monocular(32, 3, name='mono3')(x, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njyrpYWUD99_",
        "outputId": "b596ddd8-61f4-4314-d877-04aed8f96517"
      },
      "source": [
        "cnn2_1fP = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_1fP.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 1.1706 - sparse_categorical_accuracy: 0.4964 - val_loss: 0.8464 - val_sparse_categorical_accuracy: 0.7144\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.3333 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.7817\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.7315 - val_sparse_categorical_accuracy: 0.7889\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9478 - val_loss: 0.8273 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.9048 - val_sparse_categorical_accuracy: 0.7932\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.9310 - val_sparse_categorical_accuracy: 0.8014\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.9904 - val_sparse_categorical_accuracy: 0.7982\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0398 - sparse_categorical_accuracy: 0.9859 - val_loss: 1.2291 - val_sparse_categorical_accuracy: 0.7955\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.9860 - val_sparse_categorical_accuracy: 0.8262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa60411d5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K36Xi99DGaEc",
        "outputId": "604d37fb-9a5a-4891-e209-d672cdba849a"
      },
      "source": [
        "loss, acc = cnn2_1fP.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 4ms/step - loss: 0.9860 - sparse_categorical_accuracy: 0.8262\n",
            "Loss: 0.9860053062438965, Acc: 0.8262037038803101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV3QInjn_cxH"
      },
      "source": [
        "### 4) Changing number of (CMPooling + conv) layers (additional to the paper experiments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xst5okyhw8n8"
      },
      "source": [
        "# Changing the Monocular to the original one\n",
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
        "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
        "        return self.conv(pool_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59uhoXeIxI1j"
      },
      "source": [
        "2 (CMPooling + conv) layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK0craItxQHT"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left2, right2], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN-rNWMEyHTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae33ca7-08b0-4b42-bec1-3c20c0f9c20c"
      },
      "source": [
        "cnn2_2cm_conv_layers = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_2cm_conv_layers.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 12s 19ms/step - loss: 0.9695 - sparse_categorical_accuracy: 0.6055 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.7419\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9185 - val_loss: 0.7294 - val_sparse_categorical_accuracy: 0.7787\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.5286 - val_sparse_categorical_accuracy: 0.8371\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.6245 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.5494 - val_sparse_categorical_accuracy: 0.8624\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.8541\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.6163 - val_sparse_categorical_accuracy: 0.8668\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0240 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.7385 - val_sparse_categorical_accuracy: 0.8566\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.8690\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.8745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5f678f4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyT45ezwyJZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8988c9e-edc1-4fcf-bd8c-39005759eacd"
      },
      "source": [
        "loss, acc = cnn2_2cm_conv_layers.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 6s 4ms/step - loss: 0.6164 - sparse_categorical_accuracy: 0.8745\n",
            "Loss: 0.6164230704307556, Acc: 0.8745370507240295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOiT6FxCxRIQ"
      },
      "source": [
        "4 (CMPooling + conv) layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJG6PY2wxURv"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left4 = Monocular(64, 3, name='mono4_left')(tf.concat([left3, right3], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right4 = Monocular(64, 3, name='mono4_right')(tf.concat([right3, left3], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "\n",
        "    x = tf.concat([left4, right4], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-zpsYq_y-QA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e5b25c-ad6b-40a9-aaff-f5544012312f"
      },
      "source": [
        "cnn2_4cm_conv_layers = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_4cm_conv_layers.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 13s 21ms/step - loss: 1.0019 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.5754 - val_sparse_categorical_accuracy: 0.7765\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9154 - val_loss: 0.4977 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.8346\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8628\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.5164 - val_sparse_categorical_accuracy: 0.8757\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.7104 - val_sparse_categorical_accuracy: 0.8493\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.6499 - val_sparse_categorical_accuracy: 0.8395\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.5421 - val_sparse_categorical_accuracy: 0.8719\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.5279 - val_sparse_categorical_accuracy: 0.8819\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.7442 - val_sparse_categorical_accuracy: 0.8605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5fb163250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCbbsbjSzAnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9d3329-932c-43b6-b654-a19bd78d74aa"
      },
      "source": [
        "loss, acc = cnn2_4cm_conv_layers.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 6s 4ms/step - loss: 0.7442 - sparse_categorical_accuracy: 0.8605\n",
            "Loss: 0.7442200779914856, Acc: 0.8604629635810852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXtdwGQ86FH3"
      },
      "source": [
        "### 5) Without augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYVe9yF6VnJ"
      },
      "source": [
        "CNN2 without Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8OYyKn6Z7M"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    left = left_eye\n",
        "    right = right_eye\n",
        "    # \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "    \n",
        "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i_r8rFO6sMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4838146-3c5c-49b4-cbf7-62f29cf9f0f5"
      },
      "source": [
        "cnn2_WoAug = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_WoAug.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 13s 21ms/step - loss: 1.0976 - sparse_categorical_accuracy: 0.5491 - val_loss: 0.8798 - val_sparse_categorical_accuracy: 0.7065\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.2999 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.7536 - val_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.8040\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0866 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.6138 - val_sparse_categorical_accuracy: 0.8145\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.8330\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.8134\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.7541 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.8675\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.9176 - val_sparse_categorical_accuracy: 0.8323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa650254550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnSAQSp7ARP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b31a48-b70e-48bb-8712-8bf4cc218ece"
      },
      "source": [
        "loss, acc = cnn2_WoAug.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 5ms/step - loss: 0.9176 - sparse_categorical_accuracy: 0.8323\n",
            "Loss: 0.9175538420677185, Acc: 0.8323456645011902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4m84k07IULx"
      },
      "source": [
        "## Fusion of the Two Feedforward Pathways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFOEr6RsIn5A"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN2(input_shape, num_classes, scale_list):\n",
        "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
        "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
        "    \n",
        "    # parallax augmentation\n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    right = tf.concat([right_eye, parallax], axis=-1)\n",
        "    # \n",
        "    \n",
        "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
        "\n",
        "    left2 = Monocular(12, 5, name='mono2_left')(left1, scale_list=scale_list, pool_stride=1)\n",
        "    right2 = Monocular(12, 5, name='mono2_right')(right1, scale_list=scale_list, pool_stride=1)\n",
        "\n",
        "    left3 = Monocular(32, 3, name='mono3_left')(left2, scale_list=scale_list, pool_stride=1)\n",
        "    right3 = Monocular(32, 3, name='mono3_right')(right2, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    x = tf.concat([left3, right3], axis=-1)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
        "    \n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5EEo5CI91M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cb6d57-dd6b-4f35-c264-4a75d3955d63"
      },
      "source": [
        "cnn2_fu = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn2_fu.fit(train_ds , epochs=10, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 1.0221 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.8269 - val_sparse_categorical_accuracy: 0.7288\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.8192 - val_sparse_categorical_accuracy: 0.7505\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.7982 - val_sparse_categorical_accuracy: 0.8021\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 11s 19ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.8273\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.8507\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.8384\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 21ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.8524\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.6316 - val_sparse_categorical_accuracy: 0.8603\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 11s 21ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.9048 - val_sparse_categorical_accuracy: 0.8498\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 11s 20ms/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.8174 - val_sparse_categorical_accuracy: 0.8436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5dc4700d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t3PB2LOJAOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30321a3-af57-4672-9c00-96c2726ec1ed"
      },
      "source": [
        "loss, acc = cnn2_fu.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 5ms/step - loss: 0.8174 - sparse_categorical_accuracy: 0.8436\n",
            "Loss: 0.8174134492874146, Acc: 0.8435802459716797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5icoxcG8aid"
      },
      "source": [
        "# Vanilla CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74JBzOdK8bWT"
      },
      "source": [
        "def CNN(input_shape, num_classes):\n",
        "    \n",
        "    left_eye= tf.keras.Input(shape=input_shape, name = 'left_eye')\n",
        "    right_eye= tf.keras.Input(shape=input_shape, name = 'right_eye')\n",
        "    \n",
        "    parallax = left_eye - right_eye \n",
        "    x = tf.concat([left_eye, -parallax], axis=-1)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(6, 5,  activation='relu', padding= 'same', name = 'mono1_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    x = tf.keras.layers.Conv2D(12, 5, activation='relu', padding= 'same', name='mono2_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(1,1))(x)\n",
        "    x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding= 'same', name='mono3_left')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(1,1))(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
        "    feature_vector = tf.keras.layers.Flatten()(x)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='output')(feature_vector)\n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxFm7SYMlAg"
      },
      "source": [
        "def create_model(model, input_shape, num_classes):\n",
        "    m = model(input_shape, num_classes)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlJwTcDU9Jw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5024e652-56a0-406f-cb1a-b4bbf16e391d"
      },
      "source": [
        "start = time.time()\n",
        "cnn = create_model(CNN, input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=5)\n",
        "cnn.fit(train_ds , epochs=10, validation_data=test_ds)\n",
        "end = time.time()\n",
        "print(f'Running time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 14s 24ms/step - loss: 1.2436 - sparse_categorical_accuracy: 0.4623 - val_loss: 0.9235 - val_sparse_categorical_accuracy: 0.6656\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.3451 - sparse_categorical_accuracy: 0.8781 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.7811\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.1484 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.5113 - val_sparse_categorical_accuracy: 0.8454\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 13s 23ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.8698\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.8529\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 12s 22ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.8776\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 12s 23ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.8751\n",
            "Running time: 126.25021719932556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIwsFp6f9N6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a80020c-4848-4d96-83a4-ad2907b5f683"
      },
      "source": [
        "loss, acc = cnn.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 8s 5ms/step - loss: 1.3307 - sparse_categorical_accuracy: 0.7961\n",
            "Loss: 1.3306844234466553, Acc: 0.7960802316665649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVMD00Oz9ZTV"
      },
      "source": [
        "## VanillaCNN with CMPooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ8ov3is9aFz"
      },
      "source": [
        "# Concat the feature maps in different scale and convolution once. (paper version)\n",
        "class Monocular(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, ksize, **kwargs):\n",
        "        super(Monocular, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.ksize = ksize\n",
        "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
        "    \n",
        "    def call(self, fmaps, scale_list, pool_stride):\n",
        "        conv_maps = self.conv(fmaps)\n",
        "        pool_maps = cmpooling(conv_maps, scale_list, pool_stride)\n",
        "        return tf.concat(pool_maps, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Och6oMzn-4of"
      },
      "source": [
        "SCALE_LIST = [1,3,5]\n",
        "def CNN(input_shape, num_classes, scale_list):\n",
        "    \n",
        "    left_eye= tf.keras.Input(shape=input_shape, name = 'left_eye')\n",
        "    right_eye= tf.keras.Input(shape=input_shape, name = 'right_eye')\n",
        "    \n",
        "    parallax = left_eye - right_eye \n",
        "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
        "\n",
        "    y = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
        "    y = Monocular(12, 5, input_shape=input_shape, name='mono2_left')(y, scale_list=scale_list, pool_stride=1)\n",
        "    y = Monocular(32, 3, input_shape=input_shape, name='mono3_left')(y, scale_list=scale_list, pool_stride=1)\n",
        "    \n",
        "    y = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(y)\n",
        "    y = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(y)\n",
        "    y = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(y)\n",
        "    feature_vector = tf.keras.layers.Flatten()(y)\n",
        "    predicted_output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='output')(feature_vector)\n",
        "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9WNIU14My06"
      },
      "source": [
        "def create_model(model, input_shape, num_classes, scale_list):\n",
        "    m = model(input_shape, num_classes, scale_list)\n",
        "    # learning rate schedule\n",
        "    initial_learning_rate = 0.0001\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                                                              decay_rate=0.96, staircase=True)\n",
        "    \n",
        "    # compile the model\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
        "                  # Loss function to minimize\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  # List of metrics to monitor\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "                 )\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ULRq5qv-8_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e20646f-6747-47ca-fd8b-8be84f8cec79"
      },
      "source": [
        "cnn_cmp = create_model(CNN, input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=5, scale_list=SCALE_LIST)\n",
        "cnn_cmp.fit(train_ds , epochs=10, validation_data=test_ds, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "507/507 [==============================] - 12s 19ms/step - loss: 1.0960 - sparse_categorical_accuracy: 0.5486 - val_loss: 0.7567 - val_sparse_categorical_accuracy: 0.7288\n",
            "Epoch 2/10\n",
            "507/507 [==============================] - 11s 19ms/step - loss: 0.3166 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.7898\n",
            "Epoch 3/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.5295 - val_sparse_categorical_accuracy: 0.8120\n",
            "Epoch 4/10\n",
            "507/507 [==============================] - 11s 19ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.5143 - val_sparse_categorical_accuracy: 0.8313\n",
            "Epoch 5/10\n",
            "507/507 [==============================] - 11s 19ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.8394\n",
            "Epoch 6/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.5036 - val_sparse_categorical_accuracy: 0.8468\n",
            "Epoch 7/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.6149 - val_sparse_categorical_accuracy: 0.8426\n",
            "Epoch 8/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.8636\n",
            "Epoch 9/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.4800 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 10/10\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.4849 - val_sparse_categorical_accuracy: 0.8810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f359a166f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMYclcE1--0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0520dad-9f3f-45f0-a8bf-136f51c7e3cc"
      },
      "source": [
        "loss, acc = cnn_cmp.evaluate(test_ds)\n",
        "print(f\"Loss: {loss}, Acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1013/1013 [==============================] - 7s 5ms/step - loss: 0.4849 - sparse_categorical_accuracy: 0.8810\n",
            "Loss: 0.48494547605514526, Acc: 0.881049394607544\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}